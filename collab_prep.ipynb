{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9f292487",
   "metadata": {},
   "source": [
    "# Collab Runtime Check VM and GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3fa43f5",
   "metadata": {},
   "source": [
    "https://colab.research.google.com/notebooks/pro.ipynb#scrollTo=RFm2S0Gijqo8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad39a8fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import ai\n",
    "response = ai.generate_text(\"What is the capital of France?\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "383d2971",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpu_info = !nvidia-smi\n",
    "gpu_info = '\\n'.join(gpu_info)\n",
    "if gpu_info.find('failed') >= 0:\n",
    "  print('Not connected to a GPU')\n",
    "else:\n",
    "  print(gpu_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c616f85",
   "metadata": {},
   "outputs": [],
   "source": [
    "import psutil\n",
    "\n",
    "ram_gb = psutil.virtual_memory().total / 1e9\n",
    "print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n",
    "\n",
    "if ram_gb < 20:\n",
    "  print('Not using a high-RAM runtime')\n",
    "else:\n",
    "  print('You are using a high-RAM runtime!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6856743",
   "metadata": {},
   "source": [
    "# Check Runtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9607674d",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Device:\", device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db8235a6",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de2edd95",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "import os\n",
    "\n",
    "import torch\n",
    "from transformers import BertTokenizerFast, BertModel\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c329d3a",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "# Setup Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32b8311a",
   "metadata": {},
   "outputs": [],
   "source": [
    "drive.mount('/content/drive')\n",
    "\n",
    "BASE_DIR = \"/content/drive/MyDrive/ITRPA_PROJ\"   # <– your project folder\n",
    "PROCESSED_PATH = os.path.join(BASE_DIR, \"processed_data.pkl\")\n",
    "DL_PATH = os.path.join(BASE_DIR, \"dl_prepared_torch.pkl\")\n",
    "OUTPUT_DIR = os.path.join(BASE_DIR, \"outputs_colab\")\n",
    "\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "print(\"Base:\", BASE_DIR)\n",
    "print(\"Outputs:\", OUTPUT_DIR)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44ac28e7",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd426f3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(PROCESSED_PATH, \"rb\") as f:\n",
    "    data = pickle.load(f)\n",
    "\n",
    "X_train, X_test = data[\"X_train\"], data[\"X_test\"]\n",
    "y_train, y_test = data[\"y_train_enc\"], data[\"y_test_enc\"]\n",
    "\n",
    "print(f\"Train: {len(X_train)} | Test: {len(X_test)}\")\n",
    "print(\"Example:\", X_train[0][:120], \"...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97346331",
   "metadata": {},
   "source": [
    "# Initialize Bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0f428a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizerFast.from_pretrained(\"bert-base-uncased\")\n",
    "bert = BertModel.from_pretrained(\"bert-base-uncased\").to(device)\n",
    "bert.eval();  # IMPORTANT: we’re not fine-tuning here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4e1b97c",
   "metadata": {},
   "source": [
    "# LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f13b304e",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def get_token_embeddings(texts, batch_size=8, max_len=96):\n",
    "    outs = []\n",
    "    for i in range(0, len(texts), batch_size):\n",
    "        batch = texts[i:i+batch_size]\n",
    "        enc = tokenizer(batch, padding=\"max_length\", truncation=True,\n",
    "                        max_length=max_len, return_tensors=\"pt\")\n",
    "        enc = {k: v.to(device) for k, v in enc.items()}\n",
    "        last_hidden = bert(**enc).last_hidden_state   # [B, T, 768]\n",
    "        outs.append(last_hidden.cpu())\n",
    "    return torch.cat(outs, dim=0)                     # [N, T, 768]\n",
    "\n",
    "X_train_tok = get_token_embeddings(X_train, batch_size=8, max_len=96)\n",
    "X_test_tok  = get_token_embeddings(X_test,  batch_size=8, max_len=96)\n",
    "\n",
    "print(X_train_tok.shape, X_test_tok.shape)  # e.g. torch.Size([N, 96, 768])\n",
    "\n",
    "torch.save({\n",
    "    \"X_train_tok\": X_train_tok,\n",
    "    \"X_test_tok\": X_test_tok,\n",
    "    \"y_train\": torch.tensor(y_train),\n",
    "    \"y_test\": torch.tensor(y_test)\n",
    "}, os.path.join(OUTPUT_DIR, \"bert_token_emb.pt\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d9bc831",
   "metadata": {},
   "outputs": [],
   "source": [
    "pack = torch.load(os.path.join(OUTPUT_DIR, \"bert_token_emb.pt\"))\n",
    "Xtr, Xte = pack[\"X_train_tok\"], pack[\"X_test_tok\"]\n",
    "ytr, yte = pack[\"y_train\"], pack[\"y_test\"]\n",
    "\n",
    "train_ds = TensorDataset(Xtr, ytr)\n",
    "test_ds  = TensorDataset(Xte, yte)\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=16, shuffle=True)\n",
    "test_loader  = DataLoader(test_ds, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6cd706a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BertLSTMClassifier(nn.Module):\n",
    "    def __init__(self, embed_dim=768, hidden_dim=128, num_classes=3, bidirectional=True, dropout=0.3):\n",
    "        super().__init__()\n",
    "        self.lstm = nn.LSTM(embed_dim, hidden_dim,\n",
    "                            num_layers=1,\n",
    "                            batch_first=True,\n",
    "                            bidirectional=bidirectional)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.fc = nn.Linear(hidden_dim * (2 if bidirectional else 1), num_classes)\n",
    "\n",
    "    def forward(self, x):             # x: [B, T, 768]\n",
    "        out, _ = self.lstm(x)         # [B, T, 2H]\n",
    "        out = self.dropout(out[:, -1, :])  # last timestep\n",
    "        return self.fc(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff2c5e83",
   "metadata": {},
   "source": [
    "# Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9d442f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "num_classes = int(max(ytr.max().item(), yte.max().item()) + 1)\n",
    "\n",
    "model = BertLSTMClassifier(num_classes=num_classes).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=2e-4)\n",
    "\n",
    "EPOCHS = 5\n",
    "for epoch in range(EPOCHS):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for xb, yb in train_loader:\n",
    "        xb, yb = xb.to(device), yb.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        logits = model(xb)\n",
    "        loss = criterion(logits, yb)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    print(f\"Epoch {epoch+1}/{EPOCHS} - loss: {total_loss/len(train_loader):.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78949326",
   "metadata": {},
   "source": [
    "# Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddc96868",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "correct = total = 0\n",
    "with torch.no_grad():\n",
    "    for xb, yb in test_loader:\n",
    "        xb, yb = xb.to(device), yb.to(device)\n",
    "        preds = model(xb).argmax(dim=1)\n",
    "        correct += (preds == yb).sum().item()\n",
    "        total += yb.size(0)\n",
    "print(f\"BERT-LSTM Accuracy: {100*correct/total:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83032287",
   "metadata": {},
   "source": [
    "# Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2d777f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), os.path.join(OUTPUT_DIR, \"bert_lstm.pt\"))\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
