{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "machine_shape": "hm",
      "gpuType": "L4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Initial Setup"
      ],
      "metadata": {
        "id": "uwotI5d7Vvkg"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "pw1HACkygczk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e5aa5951-5d0c-4491-d392-1eca304a646a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "BASE_DIR = \"/content/drive/MyDrive/ITRPA_PROJ\"\n",
        "OUTPUT_DIR = os.path.join(BASE_DIR, \"outputs_colab\")\n",
        "\n",
        "req_path = os.path.join(BASE_DIR, \"collab_requirements.txt\")\n",
        "!pip install -q -r \"{req_path}\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def setup_paths(model_name: str):\n",
        "    base = \"/content/drive/MyDrive/ITRPA_PROJ\"\n",
        "    output = os.path.join(base, \"outputs_colab\")\n",
        "    model_dir = os.path.join(output, model_name)\n",
        "    os.makedirs(model_dir, exist_ok=True)\n",
        "    return base, output, model_dir\n"
      ],
      "metadata": {
        "id": "Q9XGDwOljEB5"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Not connected to a GPU')\n",
        "else:\n",
        "  print(gpu_info)"
      ],
      "metadata": {
        "id": "E3MoKUK3IZS3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9b9d4544-0a0c-4264-a713-2398243beaae"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sat Oct 11 20:50:32 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  NVIDIA L4                      Off |   00000000:00:03.0 Off |                    0 |\n",
            "| N/A   41C    P8             11W /   72W |       0MiB /  23034MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import psutil\n",
        "\n",
        "ram_gb = psutil.virtual_memory().total / 1e9\n",
        "print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n",
        "\n",
        "if ram_gb < 20:\n",
        "  print('Not using a high-RAM runtime')\n",
        "else:\n",
        "  print('You are using a high-RAM runtime!')"
      ],
      "metadata": {
        "id": "9oWUqllmIaoO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a1f586e4-0871-4ec3-e460-61146e08cd46"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Your runtime has 56.9 gigabytes of available RAM\n",
            "\n",
            "You are using a high-RAM runtime!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Imports"
      ],
      "metadata": {
        "id": "2-qTlJK7jGsL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "import json\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "from sklearn.preprocessing import label_binarize\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score,\n",
        "    roc_auc_score,\n",
        "    classification_report,\n",
        "    roc_curve,\n",
        "    auc,\n",
        "    confusion_matrix\n",
        ")\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\n",
        "\n",
        "from transformers import BertModel, BertTokenizer, Trainer, TrainingArguments, AutoTokenizer, AutoModel\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tqdm import tqdm\n",
        "\n",
        "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, roc_curve, auc, accuracy_score, f1_score\n",
        "import numpy as np\n",
        "\n",
        "from torchview import draw_graph\n",
        "from tqdm import tqdm\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "nf67xVEzjKOj"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load Data"
      ],
      "metadata": {
        "id": "Am3AuSLWjNzH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "DATA_DIR = os.path.join(BASE_DIR, \"data\")\n",
        "os.makedirs(DATA_DIR, exist_ok=True)\n",
        "\n",
        "def load_datafile(data_filename=\"reviews.csv\", base_dir=BASE_DIR):\n",
        "    \"\"\"\n",
        "    Loads a CSV dataset, extracts Review and Label columns,\n",
        "    maps numeric ratings (1–5) to sentiment categories,\n",
        "    and label-encodes them for modeling.\n",
        "\n",
        "    Mapping:\n",
        "        1,2 → negative\n",
        "        3   → neutral\n",
        "        4,5 → positive\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    data_filename : str\n",
        "        CSV filename (default: 'reviews.csv')\n",
        "    base_dir : str\n",
        "        Base directory (default: BASE_DIR)\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    X : pd.Series\n",
        "        Text reviews\n",
        "    y_encoded : np.ndarray\n",
        "        Encoded sentiment labels (0=negative, 1=neutral, 2=positive)\n",
        "    label_enc : LabelEncoder\n",
        "        Fitted encoder mapping sentiments to integers\n",
        "    \"\"\"\n",
        "    data_dir = os.path.join(base_dir, \"data\")\n",
        "    os.makedirs(data_dir, exist_ok=True)\n",
        "\n",
        "    data_path = os.path.join(data_dir, data_filename)\n",
        "    if not os.path.exists(data_path):\n",
        "        raise FileNotFoundError(f\"File not found: {data_path}\")\n",
        "\n",
        "    # Load and validate\n",
        "    df = pd.read_csv(data_path)\n",
        "    if not {\"Review\", \"Label\"}.issubset(df.columns):\n",
        "        raise ValueError(\"CSV must contain 'Review' and 'Label' columns.\")\n",
        "\n",
        "    # Extract X and y\n",
        "    X = df[\"Review\"].astype(str)\n",
        "    y = pd.to_numeric(df[\"Label\"], errors=\"coerce\")\n",
        "\n",
        "    # Validate label range\n",
        "    if not y.dropna().between(1, 5).all():\n",
        "        raise ValueError(\"Label column must contain numeric values 1–5.\")\n",
        "\n",
        "    # Map numeric labels to sentiment\n",
        "    y_sentiment = y.map({1: \"negative\", 2: \"negative\",\n",
        "                         3: \"neutral\",\n",
        "                         4: \"positive\", 5: \"positive\"})\n",
        "\n",
        "    # Encode sentiment labels\n",
        "    label_enc = LabelEncoder()\n",
        "    y_encoded = label_enc.fit_transform(y_sentiment)\n",
        "\n",
        "    # Summary\n",
        "    print(f\"Loaded '{data_filename}' with shape {df.shape}\")\n",
        "    print(\"Sentiment distribution:\")\n",
        "    print(y_sentiment.value_counts())\n",
        "    print(\"Label mapping:\", dict(zip(label_enc.classes_, label_enc.transform(label_enc.classes_))))\n",
        "\n",
        "    return X, y_encoded, label_enc\n",
        "\n",
        "# Example usage\n",
        "DATA_FILE = \"reviews.csv\"\n",
        "X, y, label_enc = load_datafile(DATA_FILE)\n",
        "print(\"Shapes:\", X.shape, y.shape)"
      ],
      "metadata": {
        "id": "jIuYTqGujTS5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ab1924a9-f550-45c1-cbda-5c3168331204"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded 'reviews.csv' with shape (107018, 3)\n",
            "Sentiment distribution:\n",
            "Label\n",
            "positive    97227\n",
            "neutral      5071\n",
            "negative     4720\n",
            "Name: count, dtype: int64\n",
            "Label mapping: {'negative': np.int64(0), 'neutral': np.int64(1), 'positive': np.int64(2)}\n",
            "Shapes: (107018,) (107018,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train Test Split"
      ],
      "metadata": {
        "id": "wygDF2IuE1KS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def prepare_splits(X, y, train_size=0.7, random_state=42):\n",
        "    \"\"\"\n",
        "    Splits X and y into train, validation, and test sets,\n",
        "    then fits and applies a LabelEncoder consistently across all.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    X : array-like or DataFrame\n",
        "        Input features.\n",
        "    y : array-like or Series\n",
        "        Target labels.\n",
        "    train_size : float, default=0.7\n",
        "        Proportion of data to use for training.\n",
        "    random_state : int, default=42\n",
        "        Random seed for reproducibility.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    X_train, X_val, X_test : arrays/DataFrames\n",
        "        Feature splits.\n",
        "    y_train_enc, y_val_enc, y_test_enc : arrays\n",
        "        Encoded label splits.\n",
        "    label_enc : LabelEncoder\n",
        "        Fitted LabelEncoder instance.\n",
        "    \"\"\"\n",
        "\n",
        "    # First split train vs temp (val+test)\n",
        "    X_train, X_temp, y_train, y_temp = train_test_split(\n",
        "        X, y,\n",
        "        train_size=train_size,\n",
        "        random_state=random_state,\n",
        "        stratify=y\n",
        "    )\n",
        "\n",
        "    # Split temp equally into val/test\n",
        "    X_val, X_test, y_val, y_test = train_test_split(\n",
        "        X_temp, y_temp,\n",
        "        test_size=0.5,\n",
        "        random_state=random_state,\n",
        "        stratify=y_temp\n",
        "    )\n",
        "\n",
        "    # Label encode consistently across all sets\n",
        "    label_enc = LabelEncoder()\n",
        "    label_enc.fit(list(y_train) + list(y_val) + list(y_test))\n",
        "\n",
        "    y_train_enc = label_enc.transform(y_train)\n",
        "    y_val_enc   = label_enc.transform(y_val)\n",
        "    y_test_enc  = label_enc.transform(y_test)\n",
        "\n",
        "    # Print summary\n",
        "    print(f\" Train: {len(X_train)/len(X):.1%}\")\n",
        "    print(f\" Val:   {len(X_val)/len(X):.1%}\")\n",
        "    print(f\" Test:  {len(X_test)/len(X):.1%}\")\n",
        "    print(\"Classes found:\", label_enc.classes_)\n",
        "\n",
        "    return X_train, X_val, X_test, y_train_enc, y_val_enc, y_test_enc, label_enc"
      ],
      "metadata": {
        "id": "rrCxbZK3Ee2U"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_val, X_test, y_train_enc, y_val_enc, y_test_enc, label_enc = prepare_splits(X, y)\n"
      ],
      "metadata": {
        "id": "z7nz6Dw_FwVa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f662e526-4f1d-4394-ca1f-9bc798339930"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Train: 70.0%\n",
            " Val:   15.0%\n",
            " Test:  15.0%\n",
            "Classes found: [0 1 2]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Base Model Or Embedding and CONFIG"
      ],
      "metadata": {
        "id": "u8tLWB4HHiLn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "ca9Mq1peHg3-"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "CONFIG = {\n",
        "    # ----------------- model setup -----------------\n",
        "    \"model_name\": \"bert-base-uncased\",   # swap for roberta-base etc.\n",
        "    \"num_classes\": 3,\n",
        "    \"hidden_size\": 320,\n",
        "    \"dropout\": 0.5,\n",
        "    \"activation\": \"relu\",\n",
        "    \"fine_tune_base\": True,\n",
        "\n",
        "    # ----------------- data setup ------------------\n",
        "    \"max_len\": 128,\n",
        "    \"batch_size\": 16,\n",
        "\n",
        "    # ----------------- training setup --------------\n",
        "    \"epochs\": 3,\n",
        "    \"learning_rate\": 2e-5,\n",
        "    \"optimizer\": \"adamw\",                 # 'adam', 'sgd', etc.\n",
        "    \"loss_fn\": \"crossentropy\",            # 'crossentropy', 'bce', 'mse'\n",
        "    \"device\": torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"),\n",
        "}\n"
      ],
      "metadata": {
        "id": "84h5RmqWITW2"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_base_model(model_name):\n",
        "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "    base_model = AutoModel.from_pretrained(model_name)\n",
        "    print(f\"Loaded base model: {model_name}\")\n",
        "    return tokenizer, base_model"
      ],
      "metadata": {
        "id": "qB49gGqDIjEC"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create Dataset Class"
      ],
      "metadata": {
        "id": "J7v9iSEoKL-e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class TextDataset(Dataset):\n",
        "    def __init__(self, texts, labels, tokenizer, max_len=128):\n",
        "        self.texts = texts\n",
        "        self.labels = labels\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_len = max_len\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.texts)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        enc = self.tokenizer(\n",
        "            self.texts[idx],\n",
        "            truncation=True,\n",
        "            padding=\"max_length\",\n",
        "            max_length=self.max_len,\n",
        "            return_tensors=\"pt\"\n",
        "        )\n",
        "        return {\n",
        "            \"input_ids\": enc[\"input_ids\"].squeeze(0),\n",
        "            \"attention_mask\": enc[\"attention_mask\"].squeeze(0),\n",
        "            \"labels\": torch.tensor(self.labels[idx], dtype=torch.long)\n",
        "        }"
      ],
      "metadata": {
        "id": "seCiah5SKNlf"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create Modular Models"
      ],
      "metadata": {
        "id": "h4QyVDw4KROC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class TransformerLSTMClassifier(nn.Module):\n",
        "    def __init__(self, base_model, num_classes=3, input_size=768,\n",
        "                 hidden_size=320, dropout=0.5, activation=\"relu\",\n",
        "                 fine_tune_base=True):\n",
        "        super().__init__()\n",
        "\n",
        "        self.base_model = base_model\n",
        "        self.num_classes = num_classes\n",
        "        self.input_size = input_size\n",
        "\n",
        "        # Optionally freeze transformer layers\n",
        "        for param in self.base_model.parameters():\n",
        "            param.requires_grad = fine_tune_base\n",
        "\n",
        "        # LSTM layer\n",
        "        self.lstm = nn.LSTM(\n",
        "            input_size=input_size,\n",
        "            hidden_size=hidden_size,\n",
        "            num_layers=1,\n",
        "            batch_first=True\n",
        "        )\n",
        "\n",
        "        # Dynamic activation lookup\n",
        "        activations = {\n",
        "            \"relu\": nn.ReLU(),\n",
        "            \"tanh\": nn.Tanh(),\n",
        "            \"sigmoid\": nn.Sigmoid(),\n",
        "            \"gelu\": nn.GELU(),\n",
        "            \"leakyrelu\": nn.LeakyReLU()\n",
        "        }\n",
        "        act = activations.get(activation.lower(), nn.ReLU())\n",
        "\n",
        "        # Classification head\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(hidden_size, 80),\n",
        "            act,\n",
        "            nn.Linear(80, 20),\n",
        "            act,\n",
        "            nn.Linear(20, num_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        \"\"\"\n",
        "        inputs: dict from tokenizer (input_ids, attention_mask)\n",
        "        returns: raw logits (not softmaxed)\n",
        "        \"\"\"\n",
        "        transformer_out = self.base_model(**inputs)\n",
        "        token_embeddings = transformer_out.last_hidden_state  # [batch, seq_len, hidden]\n",
        "        lstm_out, _ = self.lstm(token_embeddings)\n",
        "        last_hidden = lstm_out[:, -1, :]  # final timestep\n",
        "        logits = self.classifier(last_hidden)\n",
        "        return logits"
      ],
      "metadata": {
        "id": "xQ6Q9C5rKVpO"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create Optimizer and Loss function Helpers"
      ],
      "metadata": {
        "id": "nmogoZseMWhS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def build_optimizer(model, optimizer_name, lr):\n",
        "    optimizers = {\n",
        "        \"adamw\": torch.optim.AdamW,\n",
        "        \"adam\": torch.optim.Adam,\n",
        "        \"sgd\": torch.optim.SGD\n",
        "    }\n",
        "    if optimizer_name.lower() not in optimizers:\n",
        "        raise ValueError(f\"Unsupported optimizer: {optimizer_name}\")\n",
        "    if optimizer_name.lower() == \"sgd\":\n",
        "        return optimizers[optimizer_name.lower()](model.parameters(), lr=lr, momentum=0.9)\n",
        "    return optimizers[optimizer_name.lower()](model.parameters(), lr=lr)\n",
        "\n",
        "def build_loss(loss_name, class_weights=None):\n",
        "    loss_name = loss_name.lower()\n",
        "\n",
        "    if loss_name == \"crossentropy\":\n",
        "        if class_weights is not None:\n",
        "            return nn.CrossEntropyLoss(weight=class_weights)\n",
        "        return nn.CrossEntropyLoss()\n",
        "\n",
        "    elif loss_name == \"bce\":\n",
        "        return nn.BCEWithLogitsLoss()\n",
        "\n",
        "    elif loss_name == \"mse\":\n",
        "        return nn.MSELoss()\n",
        "\n",
        "    else:\n",
        "        raise ValueError(f\"Unsupported loss: {loss_name}\")\n"
      ],
      "metadata": {
        "id": "zj-tg5YiMi5T"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_class_weights(y_train, device):\n",
        "    \"\"\"\n",
        "    Compute balanced class weights for CrossEntropyLoss.\n",
        "\n",
        "    Args:\n",
        "        y_train: array-like of encoded class labels (e.g., [0, 1, 2, 2, 0, ...])\n",
        "        device: torch.device to move the tensor to (e.g., 'cuda' or 'cpu')\n",
        "\n",
        "    Returns:\n",
        "        class_weights: torch.Tensor of shape [num_classes]\n",
        "        weights_dict:  dict mapping class_id -> weight (for logging)\n",
        "    \"\"\"\n",
        "    y_train = np.array(y_train)\n",
        "    classes = np.unique(y_train)\n",
        "\n",
        "    weights = compute_class_weight(\n",
        "        class_weight='balanced',\n",
        "        classes=classes,\n",
        "        y=y_train\n",
        "    )\n",
        "\n",
        "    class_weights = torch.tensor(weights, dtype=torch.float).to(device)\n",
        "    weights_dict = dict(zip(classes.tolist(), weights.tolist()))\n",
        "\n",
        "    print(\"Computed class weights:\", weights_dict)\n",
        "    return class_weights, weights_dict"
      ],
      "metadata": {
        "id": "a2WEaTzYo99j"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create Data Loader Class"
      ],
      "metadata": {
        "id": "Ag7PZMPaM4PK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_dataloaders(X_train, y_train, X_val, y_val, X_test, y_test,\n",
        "                       tokenizer, max_len, batch_size):\n",
        "    def make_loader(X, y, shuffle, balance=False):\n",
        "        dataset = TextDataset(\n",
        "            texts=X.tolist() if hasattr(X, \"tolist\") else list(X),\n",
        "            labels=y.tolist() if hasattr(y, \"tolist\") else list(y),\n",
        "            tokenizer=tokenizer,\n",
        "            max_len=max_len\n",
        "        )\n",
        "\n",
        "        if balance:\n",
        "            labels = np.array(y)\n",
        "            class_counts = np.bincount(labels)\n",
        "            class_weights = 1.0 / np.maximum(class_counts, 1)\n",
        "            sample_weights = class_weights[labels]\n",
        "            sampler = WeightedRandomSampler(\n",
        "                weights=torch.DoubleTensor(sample_weights),\n",
        "                num_samples=len(sample_weights),\n",
        "                replacement=True\n",
        "            )\n",
        "            return DataLoader(dataset, batch_size=batch_size, sampler=sampler)\n",
        "        else:\n",
        "            return DataLoader(dataset, batch_size=batch_size, shuffle=shuffle)\n",
        "\n",
        "    train_loader = make_loader(X_train, y_train, shuffle=False, balance=True)   # For training\n",
        "    train_eval_loader = make_loader(X_train, y_train, shuffle=False, balance=False)  # For eval\n",
        "    val_loader   = make_loader(X_val, y_val, shuffle=False)\n",
        "    test_loader  = make_loader(X_test, y_test, shuffle=False)\n",
        "\n",
        "    print(f\"Dataloaders ready — Train: {len(train_loader.dataset)}, \"\n",
        "          f\"Val: {len(val_loader.dataset)}, Test: {len(test_loader.dataset)}\")\n",
        "    return train_loader, train_eval_loader, val_loader, test_loader\n"
      ],
      "metadata": {
        "id": "gU6wRY8LM67b"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Define Training Loop"
      ],
      "metadata": {
        "id": "U-nkZgC_O8OX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_and_evaluate(model, train_loader, val_loader, optimizer, criterion, device, model_name, model_dir, epochs=3):\n",
        "    \"\"\"\n",
        "    Train and evaluate model, log accuracy/loss, and save plots.\n",
        "    \"\"\"\n",
        "    train_losses, val_losses = [], []\n",
        "    train_accs, val_accs = [], []\n",
        "\n",
        "    model.to(device)\n",
        "\n",
        "    for epoch in range(1, epochs + 1):\n",
        "        # ---------------- TRAIN ----------------\n",
        "        model.train()\n",
        "        running_loss, correct, total = 0.0, 0, 0\n",
        "\n",
        "        for batch in tqdm(train_loader, desc=f\"Epoch {epoch}/{epochs} [Train]\", leave=False):\n",
        "            inputs = {\n",
        "                \"input_ids\": batch[\"input_ids\"].to(device),\n",
        "                \"attention_mask\": batch[\"attention_mask\"].to(device)\n",
        "            }\n",
        "            labels = batch[\"labels\"].to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss.item() * labels.size(0)\n",
        "            preds = outputs.argmax(dim=1)\n",
        "            correct += (preds == labels).sum().item()\n",
        "            total += labels.size(0)\n",
        "\n",
        "        train_loss = running_loss / total\n",
        "        train_acc = correct / total\n",
        "        train_losses.append(train_loss)\n",
        "        train_accs.append(train_acc)\n",
        "\n",
        "        # ---------------- VALIDATE ----------------\n",
        "        model.eval()\n",
        "        val_running_loss, val_correct, val_total = 0.0, 0, 0\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for batch in tqdm(val_loader, desc=f\"Epoch {epoch}/{epochs} [Val]\", leave=False):\n",
        "                inputs = {\n",
        "                    \"input_ids\": batch[\"input_ids\"].to(device),\n",
        "                    \"attention_mask\": batch[\"attention_mask\"].to(device)\n",
        "                }\n",
        "                labels = batch[\"labels\"].to(device)\n",
        "\n",
        "                outputs = model(inputs)\n",
        "                loss = criterion(outputs, labels)\n",
        "\n",
        "                val_running_loss += loss.item() * labels.size(0)\n",
        "                preds = outputs.argmax(dim=1)\n",
        "                val_correct += (preds == labels).sum().item()\n",
        "                val_total += labels.size(0)\n",
        "\n",
        "        val_loss = val_running_loss / val_total\n",
        "        val_acc = val_correct / val_total\n",
        "        val_losses.append(val_loss)\n",
        "        val_accs.append(val_acc)\n",
        "\n",
        "        # Print summary\n",
        "        print(f\"Epoch {epoch:02d}/{epochs} | \"\n",
        "              f\"Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f} | \"\n",
        "              f\"Train Acc: {train_acc*100:.2f}%, Val Acc: {val_acc*100:.2f}%\")\n",
        "\n",
        "    # ---------------- PLOTS ----------------\n",
        "    os.makedirs(model_dir, exist_ok=True)\n",
        "\n",
        "    # Loss plot\n",
        "    plt.figure(figsize=(8,5))\n",
        "    plt.plot(range(1, epochs + 1), train_losses, label=\"Train Loss\", marker='o')\n",
        "    plt.plot(range(1, epochs + 1), val_losses, label=\"Val Loss\", marker='o')\n",
        "    plt.title(f\"{model_name} Training Loss\")\n",
        "    plt.xlabel(\"Epoch\")\n",
        "    plt.ylabel(\"Loss\")\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    loss_path = os.path.join(model_dir, f\"{model_name}_training_loss.png\")\n",
        "    plt.savefig(loss_path, bbox_inches=\"tight\")\n",
        "    plt.close()\n",
        "\n",
        "    # Accuracy plot\n",
        "    plt.figure(figsize=(8,5))\n",
        "    plt.plot(range(1, epochs + 1), train_accs, label=\"Train Accuracy\", marker='o')\n",
        "    plt.plot(range(1, epochs + 1), val_accs, label=\"Val Accuracy\", marker='o')\n",
        "    plt.title(f\"{model_name} Training Accuracy\")\n",
        "    plt.xlabel(\"Epoch\")\n",
        "    plt.ylabel(\"Accuracy\")\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    acc_path = os.path.join(model_dir, f\"{model_name}_training_accuracy.png\")\n",
        "    plt.savefig(acc_path, bbox_inches=\"tight\")\n",
        "    plt.close()\n",
        "\n",
        "    print(f\"Training complete — plots saved to:\\n{loss_path}\\n{acc_path}\")\n",
        "\n",
        "    return {\n",
        "        \"train_losses\": train_losses,\n",
        "        \"val_losses\": val_losses,\n",
        "        \"train_accs\": train_accs,\n",
        "        \"val_accs\": val_accs\n",
        "    }"
      ],
      "metadata": {
        "id": "E0Zz1tbTO-4U"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Define Model Graph Function"
      ],
      "metadata": {
        "id": "fnZZrpmjQfEk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def save_model_graph(model, dataloader, model_name, model_dir, device, show_backbone=True):\n",
        "    model.eval()\n",
        "    batch = next(iter(dataloader))\n",
        "    inputs = {\n",
        "        \"input_ids\": batch[\"input_ids\"].to(device),\n",
        "        \"attention_mask\": batch[\"attention_mask\"].to(device)\n",
        "    }\n",
        "\n",
        "    if not show_backbone:\n",
        "        class DummyBase(nn.Module):\n",
        "            def __init__(self, hidden_size=768):\n",
        "                super().__init__()\n",
        "                self.config = type('obj', (object,), {\"hidden_size\": hidden_size})\n",
        "\n",
        "            def forward(self, **kwargs):\n",
        "                batch_size = kwargs[\"input_ids\"].shape[0]\n",
        "                seq_len = kwargs[\"input_ids\"].shape[1]\n",
        "                hidden_size = self.config.hidden_size\n",
        "                return type('obj', (object,), {\n",
        "                    \"last_hidden_state\": torch.randn(\n",
        "                        batch_size, seq_len, hidden_size,\n",
        "                        device=kwargs[\"input_ids\"].device\n",
        "                    )\n",
        "                })\n",
        "\n",
        "        model.base_model = DummyBase()\n",
        "\n",
        "    class TorchViewWrapper(nn.Module):\n",
        "        def __init__(self, model):\n",
        "            super().__init__()\n",
        "            self.model = model\n",
        "        def forward(self, inputs):\n",
        "            return self.model(inputs)\n",
        "\n",
        "    wrapped_model = TorchViewWrapper(model).to(device)\n",
        "    wrapped_model.eval()\n",
        "\n",
        "    graph = draw_graph(\n",
        "        wrapped_model,\n",
        "        input_data=(inputs,),\n",
        "        expand_nested=True,\n",
        "        depth=4,\n",
        "        device=device,\n",
        "        save_graph=True,\n",
        "        directory=model_dir,\n",
        "        filename=f\"{model_name.replace('/', '_')}_graph\"\n",
        "    )\n",
        "\n",
        "    print(f\"✅ Saved model graph to: {model_dir}/{model_name.replace('/', '_')}_graph.png\")\n",
        "    return graph\n"
      ],
      "metadata": {
        "id": "DGTueAqlQkbV"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Define Evaluation Loop"
      ],
      "metadata": {
        "id": "51kRq4ZdRAFR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_model(\n",
        "    model,\n",
        "    test_loader,\n",
        "    label_encoder,\n",
        "    device,\n",
        "    model_name,\n",
        "    model_dir,\n",
        "    num_classes=3,\n",
        "    train_acc_final=None\n",
        "):\n",
        "    \"\"\"\n",
        "    Evaluate a trained model on the test set and visualize key metrics.\n",
        "\n",
        "    Saves:\n",
        "        - classification_report.json\n",
        "        - roc_auc.png\n",
        "        - confusion_matrix.png\n",
        "        - accuracy_barplot.png (if train_acc_final provided)\n",
        "    \"\"\"\n",
        "    os.makedirs(model_dir, exist_ok=True)\n",
        "    model.to(device)\n",
        "    model.eval()\n",
        "\n",
        "    all_preds, all_probs, all_labels = [], [], []\n",
        "    with torch.no_grad():\n",
        "        for batch in tqdm(test_loader, desc=f\"Evaluating {model_name}\", leave=False):\n",
        "            inputs = {\n",
        "                \"input_ids\": batch[\"input_ids\"].to(device),\n",
        "                \"attention_mask\": batch[\"attention_mask\"].to(device)\n",
        "            }\n",
        "            labels = batch[\"labels\"].to(device)\n",
        "            outputs = model(inputs)\n",
        "            probs = torch.softmax(outputs, dim=1)\n",
        "            preds = torch.argmax(probs, dim=1)\n",
        "\n",
        "            all_preds.extend(preds.cpu().numpy())\n",
        "            all_probs.extend(probs.cpu().numpy())\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "    preds = np.array(all_preds)\n",
        "    probs = np.array(all_probs)\n",
        "    labels = np.array(all_labels)\n",
        "\n",
        "    # Decode to class names\n",
        "    y_true = label_encoder.inverse_transform(labels)\n",
        "    y_pred = label_encoder.inverse_transform(preds)\n",
        "    class_names = label_encoder.classes_\n",
        "\n",
        "    # ---------------- Classification report ----------------\n",
        "    report = classification_report(\n",
        "        y_true, y_pred, target_names=class_names,\n",
        "        output_dict=True, zero_division=0\n",
        "    )\n",
        "    report = {str(k): v for k, v in report.items()}\n",
        "    report_path = os.path.join(model_dir, f\"{model_name}_classification_report.json\")\n",
        "    with open(report_path, \"w\") as f:\n",
        "        json.dump(report, f, indent=4)\n",
        "    print(f\"Classification report saved → {report_path}\")\n",
        "\n",
        "    # ---------------- ROC-AUC ----------------\n",
        "    y_true_bin = label_binarize(labels, classes=np.arange(num_classes))\n",
        "    fpr, tpr, roc_auc = {}, {}, {}\n",
        "\n",
        "    for i in range(num_classes):\n",
        "        # Some classes might not appear in test set → handle safely\n",
        "        if y_true_bin[:, i].sum() == 0:\n",
        "            fpr[i], tpr[i], roc_auc[i] = [0], [0], 0.0\n",
        "            continue\n",
        "        fpr[i], tpr[i], _ = roc_curve(y_true_bin[:, i], probs[:, i])\n",
        "        roc_auc[i] = auc(fpr[i], tpr[i])\n",
        "\n",
        "    # Macro AUC (multi-class One-vs-Rest)\n",
        "    macro_auc = roc_auc_score(\n",
        "        y_true_bin, probs, average=\"macro\", multi_class=\"ovr\"\n",
        "    )\n",
        "\n",
        "    plt.figure(figsize=(7, 6))\n",
        "    for i, name in enumerate(class_names):\n",
        "        plt.plot(fpr[i], tpr[i], lw=2, label=f\"{name} (AUC={roc_auc[i]:.3f})\")\n",
        "    plt.plot([0, 1], [0, 1], \"k--\", lw=1)\n",
        "    plt.title(f\"{model_name} ROC Curves (Macro AUC={macro_auc:.3f})\")\n",
        "    plt.xlabel(\"False Positive Rate\")\n",
        "    plt.ylabel(\"True Positive Rate\")\n",
        "    plt.legend(loc=\"lower right\")\n",
        "    plt.grid(True)\n",
        "\n",
        "    roc_path = os.path.join(model_dir, f\"{model_name}_roc_auc.png\")\n",
        "    plt.savefig(roc_path, bbox_inches=\"tight\")\n",
        "    plt.close()\n",
        "    print(f\"ROC-AUC plot saved → {roc_path}\")\n",
        "\n"
      ],
      "metadata": {
        "id": "xgK_Mj_eRCbp"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# USAGE"
      ],
      "metadata": {
        "id": "M8HQuZUfLOCV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "MODEL_NAME = \"bert_lstm\"\n",
        "MODEL_DIR = os.path.join(OUTPUT_DIR, MODEL_NAME)\n",
        "os.makedirs(MODEL_DIR, exist_ok=True)\n",
        "\n",
        "# ---------------- CONFIG ----------------\n",
        "CONFIG['model_name']     = \"bert-base-uncased\"\n",
        "CONFIG['activation']     = \"sigmoid\"\n",
        "CONFIG['hidden_size']    = 320\n",
        "CONFIG['dropout']        = 0.5\n",
        "CONFIG['fine_tune_base'] = True\n",
        "CONFIG['num_classes']    = 3\n",
        "\n",
        "CONFIG['max_len']        = 128\n",
        "CONFIG['batch_size']     = 16\n",
        "\n",
        "CONFIG['epochs']         = 2\n",
        "CONFIG['learning_rate']  = 2e-5\n",
        "CONFIG['optimizer']      = \"adamw\"\n",
        "CONFIG['loss_fn']        = \"crossentropy\"\n",
        "\n",
        "CONFIG['device']         = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# ---------------- Load tokenizer + transformer ----------------\n",
        "tokenizer, base_model = load_base_model(CONFIG[\"model_name\"])\n",
        "\n",
        "# ---------------- Initialize model ----------------\n",
        "model = TransformerLSTMClassifier(\n",
        "    base_model     = base_model,\n",
        "    num_classes    = CONFIG['num_classes'],\n",
        "    input_size     = base_model.config.hidden_size,\n",
        "    hidden_size    = CONFIG['hidden_size'],\n",
        "    dropout        = CONFIG['dropout'],\n",
        "    activation     = CONFIG['activation'],\n",
        "    fine_tune_base = CONFIG['fine_tune_base']\n",
        ").to(CONFIG['device'])\n",
        "\n",
        "# ---------------- Compute Class Weights ----------------\n",
        "class_weights, weights_dict = compute_class_weights(y_train_enc, CONFIG[\"device\"])\n",
        "print(\"Computed class weights:\", weights_dict)\n",
        "\n",
        "# --- Visualize class distribution ---\n",
        "y_train_np = np.array(y_train_enc)\n",
        "unique, counts = np.unique(y_train_np, return_counts=True)\n",
        "\n",
        "plt.figure(figsize=(6, 4))\n",
        "plt.bar(unique, counts, color=[\"#f44336\", \"#ff9800\", \"#4caf50\"])\n",
        "plt.xticks(unique, [f\"Class {c}\" for c in unique])\n",
        "plt.title(\"Training Label Distribution\")\n",
        "plt.xlabel(\"Class Label\")\n",
        "plt.ylabel(\"Sample Count\")\n",
        "\n",
        "for i, count in enumerate(counts):\n",
        "    plt.text(i, count + max(counts)*0.01, str(count), ha=\"center\", fontsize=10)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# ---------------- Optimizer and loss ----------------\n",
        "optimizer = build_optimizer(model, CONFIG[\"optimizer\"], CONFIG[\"learning_rate\"])\n",
        "criterion = build_loss(CONFIG[\"loss_fn\"])\n",
        "\n",
        "# ---------------- Dataloaders ----------------\n",
        "train_dataloader, train_eval_dataloader, val_dataloader, test_dataloader = create_dataloaders(\n",
        "    X_train, y_train_enc,\n",
        "    X_val,   y_val_enc,\n",
        "    X_test,  y_test_enc,\n",
        "    tokenizer,\n",
        "    CONFIG[\"max_len\"],\n",
        "    CONFIG[\"batch_size\"]\n",
        ")\n",
        "\n",
        "# ---------------- Training ----------------\n",
        "history = train_and_evaluate(\n",
        "    model=model,\n",
        "    train_loader=train_dataloader,\n",
        "    val_loader=val_dataloader,\n",
        "    optimizer=optimizer,\n",
        "    criterion=criterion,\n",
        "    device=CONFIG[\"device\"],\n",
        "    model_name=MODEL_NAME,  # safe filename\n",
        "    model_dir=MODEL_DIR,\n",
        "    epochs=CONFIG[\"epochs\"]\n",
        ")\n",
        "\n",
        "# ---------------- Model Graph ----------------\n",
        "save_model_graph(\n",
        "    model,\n",
        "    train_dataloader,\n",
        "    CONFIG[\"model_name\"],\n",
        "    MODEL_DIR,\n",
        "    CONFIG[\"device\"],\n",
        "    show_backbone=True\n",
        ")\n",
        "\n",
        "# ---------------- Evaluation ----------------\n",
        "results = evaluate_model(\n",
        "    model=model,\n",
        "    test_loader=test_dataloader,\n",
        "    label_encoder=label_enc,\n",
        "    device=CONFIG[\"device\"],\n",
        "    model_name=MODEL_NAME,\n",
        "    model_dir=MODEL_DIR,\n",
        "    num_classes=CONFIG[\"num_classes\"],\n",
        "    train_acc_final=history[\"train_accs\"][-1]\n",
        ")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Koozh2YyLAzj",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 774
        },
        "outputId": "be6b32ed-b800-47fa-f176-acefb4260446"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded base model: bert-base-uncased\n",
            "Computed class weights: {0: 7.557707828894269, 1: 7.0339906103286385, 2: 0.36690273981995747}\n",
            "Computed class weights: {0: 7.557707828894269, 1: 7.0339906103286385, 2: 0.36690273981995747}\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 600x400 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataloaders ready — Train: 74912, Val: 16053, Test: 16053\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 01/2 | Train Loss: 0.8051, Val Loss: 0.6214 | Train Acc: 79.89%, Val Acc: 89.63%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 02/2 | Train Loss: 0.4843, Val Loss: 0.4972 | Train Acc: 89.06%, Val Acc: 85.59%\n",
            "Training complete — plots saved to:\n",
            "/content/drive/MyDrive/ITRPA_PROJ/outputs_colab/bert_lstm/bert_lstm_training_loss.png\n",
            "/content/drive/MyDrive/ITRPA_PROJ/outputs_colab/bert_lstm/bert_lstm_training_accuracy.png\n",
            "✅ Saved model graph to: /content/drive/MyDrive/ITRPA_PROJ/outputs_colab/bert_lstm/bert-base-uncased_graph.png\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "evaluate_model() got an unexpected keyword argument 'train_loader'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1138867009.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;31m# ---------------- Evaluation ----------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m results = evaluate_model(\n\u001b[0m\u001b[1;32m     97\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[0mtrain_loader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_eval_dataloader\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# unbalanced version\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: evaluate_model() got an unexpected keyword argument 'train_loader'"
          ]
        }
      ]
    }
  ]
}